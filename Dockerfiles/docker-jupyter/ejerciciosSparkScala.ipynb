{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: RDD Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "val elements = List(\"claro\", \"corona\", \"telcel\", \"cemex\", \"claro\", \"bimbo\", \"oxxo\", \"bigdata\", \"bbva\", \"banamex\", \"claro\")\n",
    "val elementsRDD = sc.parallelize(elements)\n",
    "elementsRDD.glom().take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "elementsRDD.map(word => word.toUpperCase).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val collectionElements = sc.parallelize(List(List(1,2,3), List(1), List(3,4,5,6)))\n",
    "collectionElements.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "collectionElements.flatMap(listas => listas).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val listToFilter = sc.parallelize(List(\"paranoid android\",\"nude\",\"no surprises\",\"house of cards\",\"airbag\",\"creep\"))\n",
    "listToFilter.filter(song => song.startsWith(\"n\")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val listToGroup = sc.parallelize(List(\"Rodrigo\", \"Lucas\", \"Mauricio\", \"Marcos\", \"Carlos\", \"Camilo\", \"Romina\", \"Ruben\"))\n",
    "val listGrouped = listToGroup.groupBy(nombre => nombre.charAt(0))\n",
    "listGrouped.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val pairRDD = sc.parallelize(List(('a', 10),('b', 9),('a', 5),('a', 9),('b', 8),('b', 8)))\n",
    "val pairRDDGrouped = pairRDD.groupByKey()\n",
    "pairRDDGrouped.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val pairRDDRBK = pairRDD.reduceByKey((v1, v2) => v1 + v2)\n",
    "pairRDDRBK.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val x = sc.parallelize(List((\"a\", 1), (\"b\", 2), (\"c\", 6)))\n",
    "val y = sc.parallelize(List((\"a\", 3), (\"a\", 4), (\"b\", 5)))\n",
    "\n",
    "x.join(y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val x = sc.parallelize(List((\"a\", 1), (\"a\", 2), (\"a\", 1), (\"a\", 3)))\n",
    "x.distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val numbersRDD = sc.parallelize(1 until 51 toList)\n",
    "numbersRDD.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "numbersRDD.coalesce(2).getNumPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val x = sc.parallelize(List(1, 2, 3 , 4, 5))\n",
    "val y = sc.parallelize(List(\"a\", \"b\", \"c\", \"d\", \"e\"))\n",
    "\n",
    "x.zip(y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "elementsRDD.reduce((w1, w2) => w1 + w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "## word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Generate RDD from scala list\n",
    "val wordList =  List(\"boat\",\"cat\",\"house\",\"river\",\"boat\",\"rat\",\"elephant\")\n",
    "val wordsRDD =  sc.parallelize(wordList)\n",
    "wordsRDD.getClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Create a function to pluralize simple words\n",
    "def makePlural(word: String): String = {\n",
    "     word+\"s\"\n",
    "}\n",
    "\n",
    "print(makePlural(\"cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Apply makePlural function to RDD\n",
    "val pluralRDD =  wordsRDD.map(x => makePlural(x))// FILLIN\n",
    "pluralRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Apply lambda function to pluralize simple words\n",
    "val pluralLambdaRDD = wordsRDD.map(_ + 's')\n",
    "pluralLambdaRDD.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Make RDD with length of each word\n",
    "val pluralLengths = pluralRDD.map(word => word.size)\n",
    "pluralLengths.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Word count\n",
    "\n",
    "// From wordsRDD create a pair RDD where each element is a pair tuple (k, v) consisting of (<word>, 1)\n",
    "// using map()\n",
    "\n",
    "val wordPairs = wordsRDD.map(word =>(word, 1))\n",
    "wordPairs.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// count each word with groupByKey approach\n",
    "\n",
    "val wordsGrouped = wordPairs.groupByKey \n",
    "wordsGrouped.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// get the v size for count each word\n",
    "val wordCountsGrouped = wordsGrouped.map(pair => (pair._1, pair._2.size ))\n",
    "wordCountsGrouped.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// count by key approach\n",
    "wordPairs.countByKey.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// reduceByKey approach\n",
    "val wordCounts = wordPairs.reduceByKey(_ + _)\n",
    "wordCounts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// all together with reduce by key\n",
    "\n",
    "val wordCountsCollected = wordsRDD.map(w => (w, 1)).reduceByKey(_ + _)\n",
    "wordCountsCollected.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// count unique words\n",
    "val uniqueWords = wordCountsCollected.count\n",
    "uniqueWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Finding the mean number of words per unique\n",
    "val totalCount = wordCountsCollected.map(x => x._2).reduce(_ + _) \n",
    "val average = totalCount / wordCounts.count.toDouble\n",
    "println(totalCount)\n",
    "print(wordCounts.count.toDouble)\n",
    "\"%.2f\".format(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// wordCount function\n",
    "\n",
    "import org.apache.spark.rdd.RDD\n",
    "def wordCount(rdd: RDD[String]): RDD[(String, Int)] = {\n",
    "    rdd.map(x => (x, 1)).reduceByKey((a, b) => a + b)\n",
    "}\n",
    "wordCount(wordsRDD).collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// RemovePunctuation function\n",
    "\n",
    "def removePunctuation(text: String): String = {\n",
    "    val regex = \"([^A-Za-z1-9 ]*)\".r\n",
    "    regex.replaceAllIn(text, \"\").trim.toLowerCase\n",
    "}\n",
    "\n",
    "println(removePunctuation(\"Hi, you!\"))\n",
    "println(removePunctuation(\" No under_score!\"))\n",
    "println(removePunctuation(\" *      Remove punctuation then spaces  * \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val shakespeareString = \"\"\"\n",
    "Project Gutenberg’s The Complete Works of William Shakespeare, by William\n",
    "Shakespeare\n",
    "\n",
    "This eBook is for the use of anyone anywhere in the United States and\n",
    "most other parts of the world at no cost and with almost no restrictions\n",
    "whatsoever.  You may copy it, give it away or re-use it under the terms\n",
    "of the Project Gutenberg License included with this eBook or online at\n",
    "www.gutenberg.org.  If you are not located in the United States, you’ll\n",
    "have to check the laws of the country where you are located before using\n",
    "this ebook.\n",
    "\n",
    "See at the end of this file: * CONTENT NOTE (added in 2017) *\n",
    "\n",
    "\n",
    "Title: The Complete Works of William Shakespeare\n",
    "\n",
    "Author: William Shakespeare\n",
    "\n",
    "Release Date: January 1994 [EBook #100]\n",
    "Last Updated: February 19, 2018\n",
    "\n",
    "Language: English\n",
    "\n",
    "Character set encoding: UTF-8\n",
    "\n",
    "*** START OF THIS PROJECT GUTENBERG EBOOK THE COMPLETE WORKS OF WILLIAM SHAKESPEARE ***\n",
    "\n",
    "\n",
    "\n",
    "The Complete Works of William Shakespeare\n",
    "\n",
    "\n",
    "\n",
    "by William Shakespeare\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Create RDD\n",
    "val shakespeareRDD = sc.parallelize(shakespeareString.split('\\n'))\n",
    "\n",
    "shakespeareRDD.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// clean empty lines an punctuation\n",
    "val shakespeareRDDclean = shakespeareRDD.filter(x => x != \"\").map(x => removePunctuation(x))\n",
    "shakespeareRDDclean.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Words from lines\n",
    "val shakespeareWordsRDD = shakespeareRDDclean.flatMap(x => x.split(\" \"))\n",
    "shakespeareWordsRDD.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shakespeareWordsRDD.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// count empty words\n",
    "shakespeareWordsRDD.filter(x => x == \"\").count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// clean empty words\n",
    "val shakeWordsRDD = shakespeareWordsRDD.filter(_ != \"\")\n",
    "shakeWordsRDD.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "val shakeWordCount = wordCount(shakeWordsRDD)\n",
    "shakeWordCount.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shakeWordCount.map(x => (x._2, x._1)).sortByKey(false).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shakeWordCount.getNumPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: DataFrame review\n",
    "\n",
    "## DataFrame creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Case class approach\n",
    "\n",
    "val spark2 = spark\n",
    "\n",
    "case class Emp(name: String, age: Int, sex: String, emp: String)\n",
    "case class Company(emp: String, emp_type: String)\n",
    "\n",
    "import spark2.sqlContext.implicits._\n",
    "\n",
    "\n",
    "\n",
    "val peopleList = Seq(new Emp(\"Mauro\", 46, \"Hombre\", \"BBVA\"),\n",
    "              new Emp(\"Maribel\", 30, \"Mujer\", \"Banamex\"),\n",
    "              new Emp(\"Marcos\", 40, \"Hombre\", \"Banamex\"),\n",
    "              new Emp(\"Ruben\", 42, \"Hombre\", \"BBVA\"),\n",
    "              new Emp(\"Ruben\", 42, \"Hombre\", \"BBVA\"),\n",
    "              new Emp(\"Pepe\", 42, \"Hombre\", \"Banamex\"),\n",
    "              new Emp(\"Sarai\", 27, \"Mujer\", \"Banamex\"))\n",
    "                            \n",
    "val peopleRDD = sc.parallelize(peopleList)\n",
    "\n",
    "val peopleDF = peopleRDD.toDF()\n",
    "\n",
    "peopleDF.printSchema\n",
    "//peopleDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// StrucType approach\n",
    "import org.apache.spark.sql.types.StructType\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType}\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val schema = new StructType().add(\"name\", StringType, true).add(\"age\", IntegerType, true).add(\"sex\", StringType, true).add(\"emp\", StringType, true)\n",
    "\n",
    "val peopleRowRDD = peopleRDD.map(x => Row(x.name, x.age, x.sex, x.emp))\n",
    "\n",
    "val peopleDFSchema = spark.createDataFrame(peopleRowRDD, schema)\n",
    "peopleDFSchema.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// select\n",
    "peopleDFSchema.select(\"age\", \"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// select distinct\n",
    "\n",
    "peopleDFSchema.select(\"emp\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// describe\n",
    "peopleDFSchema.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// pivot 1\n",
    "\n",
    "peopleDFSchema.groupBy(\"name\").pivot(\"emp\").count().orderBy(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// pivot 2\n",
    "\n",
    "peopleDFSchema.groupBy(\"age\").pivot(\"sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "peopleDFSchema.groupBy(\"sex\").pivot(\"sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// dropDuplicates\n",
    "peopleDFSchema.dropDuplicates().groupBy(\"age\").pivot(\"sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// groupBy\n",
    "peopleDFSchema.groupBy(\"emp\").agg(\"age\" -> \"mean\", \"sex\" -> \"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// orderBy\n",
    "import org.apache.spark.sql.functions._\n",
    "peopleDFSchema.orderBy(asc(\"name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// add new colum with operation over an existing column\n",
    "\n",
    "peopleDFSchema.withColumn(\"sex_type\", col(\"sex\").substr(0,1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// add new column with literal value\n",
    "peopleDFSchema.withColumn(\"literal\", lit(10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// Apply sql querys to dataframe\n",
    "peopleDFSchema.createOrReplaceTempView(\"people_view\")\n",
    "spark.sql(\"select age, count(emp) from people_view group by age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// tuple access\n",
    "(\"BBVA\", \"Banamex\")._1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "// join\n",
    "import org.apache.spark.sql.types.StructType\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType}\n",
    "import org.apache.spark.sql.Row\n",
    "// FILLIN: create case class Company\n",
    "case class Company(emp: String, emp_type: String)\n",
    "\n",
    "import spark.sqlContext.implicits._\n",
    "\n",
    "val schema = new StructType().add(\"emp\", StringType, true).add(\"emp_type\", StringType, true)\n",
    "// FILLIN: create schema with columns emp: String, emp_type String\n",
    "\n",
    "\n",
    "\n",
    "val coSeq = Seq((\"BBVA\",\"bank\"),(\"Banamex\", \"otherBank\"))\n",
    "val coRDD = sc.parallelize(coSeq)\n",
    "\n",
    "//val coRowRDD =  // FILLIN map coRDD tuples to rows\n",
    "val coRowRDD = coRDD.map(x => Row(x._1,x._2))\n",
    "val coDFSchema = spark.createDataFrame(coRowRDD, schema)\n",
    "coDFSchema.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "peopleDFSchema.join(coDFSchema, \"emp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "peopleDFSchema.alias(\"a\").join(coDFSchema.alias(\"b\"), $\"a.emp\" === $\"b.emp\" && $\"a.sex\" === \"Mujer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
